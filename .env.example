# Supabase (create project at https://supabase.com)
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
# Required only for scripts/create-example-user.ts (do not expose in client)
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# LiteLLM proxy – all embedding/LLM requests go through the proxy. See litellm/config.yaml.
LITELLM_EMBEDDING_API_BASE=http://localhost:4000
LITELLM_EMBEDDING_API_KEY=sk-1234
LITELLM_EMBEDDING_MODEL=minimax-embed

# Proxy backend keys (loaded when you run "bun run proxy"). For minimax-embed set:
#   MINIMAX_API_KEY, MINIMAX_GROUP_ID, OPENAI_API_KEY=<same as MINIMAX_API_KEY>
# For featherless-embed (chat only; no embeddings): FEATHERLESS_API_KEY, OPENAI_API_KEY=<same>
MINIMAX_API_KEY=
MINIMAX_GROUP_ID=
OPENAI_API_KEY=

# For Phase 3 lesson generation – use Featherless (works in Hong Kong and globally); no OpenAI required.
# Set FEATHERLESS_API_KEY (get key at https://featherless.ai). Optional: FEATHERLESS_CHAT_MODEL (default: Qwen/Qwen2.5-7B-Instruct).
# Alternatively use OpenAI: set OPENAI_API_KEY and optionally OPENAI_API_BASE.
# Optional: OPENAI_EMBEDDING_API_KEY – if set, used as fallback when LiteLLM proxy returns 404 for embeddings (e.g. when using featherless-embed; Featherless has no embeddings API).
# FEATHERLESS_API_KEY=
# FEATHERLESS_CHAT_MODEL=Qwen/Qwen2.5-7B-Instruct
# OPENAI_EMBEDDING_API_KEY=
